{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/naodell/work/hgcal/analysis\n"
     ]
    }
   ],
   "source": [
    "# imports and setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd '/home/naodell/work/hgcal/analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('default')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from models.autoencoder import AutoEncoderModular\n",
    "from models.loss import mse_loss_regularized\n",
    "from datasets.hgcal_tc_dataset import HGCalTCModuleDataset\n",
    "\n",
    "#%connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m split \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(\u001b[38;5;241m0.8\u001b[39m\u001b[38;5;241m*\u001b[39mn_total)\n\u001b[1;32m     13\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(hgcal_data[:split],  batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 14\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(\u001b[43mhgcal_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m,  batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal number of events: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_total\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/work/hgcal/analysis/datasets/hgcal_tc_dataset.py:69\u001b[0m, in \u001b[0;36mHGCalTCModuleDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m---> 69\u001b[0m     wafer, uv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwafer_data[index]\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m#y = self.targets[index]\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "# get the data\n",
    "input_dir = 'local_data/econ_training_data/single_photon_data/'\n",
    "input_filenames = [f'{input_dir}/{f}' for f in os.listdir(input_dir)]\n",
    "hgcal_data = HGCalTCModuleDataset(input_filenames)\n",
    "\n",
    "# sample from dataframe according to event weights; split into testing and training sets\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# training sample\n",
    "batch_size = 8\n",
    "n_total = len(hgcal_data)\n",
    "split = round(0.8*n_total)\n",
    "train_loader = DataLoader(hgcal_data[:split],  batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(hgcal_data[split:],  batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "print(f'Total number of events: {n_total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define and setup the NN model\n",
    "scenario = 'modular'\n",
    "model = AutoEncoderModular([(1, 1)]).to(device)\n",
    "print(device, model, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize NN weights\n",
    "n_epochs = 20\n",
    "n_events = len(train_loader)\n",
    "\n",
    "# define loss and configure optimizer\n",
    "loss_fn = nn.HuberLoss(reduction='sum')\n",
    "#loss_fn = mse_loss_regularized\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-2, weight_decay=1e-3)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "tb_writer = SummaryWriter(log_dir='logs')\n",
    "\n",
    "pbar1 = tqdm(range(n_epochs), total=n_epochs, leave=False, position=0)\n",
    "pbar1.set_postfix({'avg. loss':'?'})\n",
    "loss_cache = []\n",
    "for iepoch in pbar1:\n",
    "    model.train()\n",
    "    pbar2 = tqdm(train_loader, total=n_events, leave=False, position=1)\n",
    "    pbar2.set_postfix({'loss':'?'})\n",
    "    avg_loss = 0\n",
    "    for jevent, features in enumerate(pbar2):\n",
    "        features = features.unsqueeze(1).to(device)\n",
    "        #targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        features_pred = model(features, '(1, 1)')\n",
    "        loss = loss_fn(torch.log(1. + features_pred), torch.log(1. + features))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #pbar2.set_postfix({'loss':f'{loss.item():.3f}'})\n",
    "        #tb_writer.add_scalar('training loss', loss.item(), iepoch*n_events + jevent)\n",
    "        \n",
    "        avg_loss += loss.item()\n",
    "        if jevent%1000 == 0:\n",
    "            avg_loss /= 1000\n",
    "            pbar2.set_postfix({'loss':f'{loss.item():.3f}'})\n",
    "            #tb_writer.add_scalar('training loss', avg_loss, iepoch*(n_events//1000) + jevent/1000)\n",
    "            tb_writer.add_scalar('training loss', loss.item(), iepoch*(n_events//1000) + jevent/1000)\n",
    "            avg_loss = 0\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        n_test_events = len(test_loader)\n",
    "        for features in tqdm(test_loader, total=n_test_events, leave=False):\n",
    "            features = features.unsqueeze(1).to(device)\n",
    "            #targets = targets.to(device)\n",
    "            features_pred = model(features, '(1, 1)')\n",
    "            #tqdm.write(features_pred.shape, features.shape)\n",
    "            test_loss += loss_fn(torch.log(1. + features_pred), torch.log(1. + features))\n",
    "            loss_cache.append(test_loss.item())\n",
    "            \n",
    "            \n",
    "        avg_loss = test_loss.item()/n_test_events\n",
    "        pbar1.set_postfix({'avg loss':f'{avg_loss:.3f}'})\n",
    "        tb_writer.add_scalar('test loss', avg_loss, iepoch)\n",
    "        #tb_writer.add_graph(model, features)\n",
    "        \n",
    "        #images = torchvision.utils.make_grid(features)\n",
    "        #images_pred = torchvision.utils.make_grid(features_pred)\n",
    "        #tb_writer.add_image('input', images)\n",
    "        #tb_writer.add_image('output', images_pred)\n",
    "        \n",
    "        # write a checkpoint based on the performance of the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare images\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 8, facecolor='white', figsize=(12, 5), sharey=False, sharex=False)\n",
    "    images = iter(test_loader).next()\n",
    "    images = images.unsqueeze(1).to(device)\n",
    "    images_pred = model(images, '(1, 1)')\n",
    "    #encoded_images = model.encoder_dict['1 1'](images)\n",
    "    encoded_images = model.encode(images, '(1, 1)')\n",
    "    for ix, (image, encoded_image, image_pred) in enumerate(zip(images, encoded_images, images_pred)):\n",
    "        image = image.squeeze().cpu().numpy()\n",
    "        encoded_image = encoded_image.squeeze().cpu().numpy()\n",
    "        image_pred = image_pred.squeeze().cpu().numpy().reshape(image.shape)\n",
    "        energy_corr = image.sum()/image_pred.sum()\n",
    "        image_pred *= energy_corr\n",
    "        \n",
    "        ax = axes[0][ix]\n",
    "        ax.imshow(image, norm=LogNorm(vmin=0.1, vmax=100))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if ix == 0:\n",
    "            ax.set_ylabel('input')\n",
    "        \n",
    "        ax = axes[1][ix]\n",
    "        ax.imshow(encoded_image.reshape(-1, 2), norm=LogNorm(vmin=0.1, vmax=100))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if ix == 0:\n",
    "            ax.set_ylabel('encoded')\n",
    "            \n",
    "        ax = axes[2][ix]\n",
    "        ax.imshow(image_pred*energy_corr, norm=LogNorm(vmin=0.1, vmax=100))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if ix == 0:\n",
    "            ax.set_ylabel('output')\n",
    "        \n",
    "        #ax = axes[3][ix]\n",
    "        #image[image ==  0] = 0.1\n",
    "        #ax.imshow(abs(image - image_pred)/image, cmap='coolwarm')\n",
    "        #ax.set_xticks([])\n",
    "        #ax.set_yticks([])\n",
    "        #if ix == 0:\n",
    "        #    ax.set_ylabel('input - output')\n",
    "            \n",
    "        #plt.colorbar()\n",
    "        \n",
    "        if ix == 9: break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/ae_encoding_comparisons_modular_{scenario}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the the total error for both total energy and \n",
    "energy_diff = []\n",
    "energy_sums = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    n_test_events = len(test_loader)\n",
    "    for features in tqdm(test_loader, total=n_test_events, leave=False):\n",
    "        features = features.unsqueeze(1).to(device)\n",
    "        #targets = targets.to(device)\n",
    "        features_pred = model(features, '(1, 1)').squeeze()\n",
    "        features = features.squeeze()\n",
    "        e_sum = features.sum(dim=(1, 2))\n",
    "        e_sum_pred = features_pred.sum(dim=(1, 2))\n",
    "        #energy_sum_pred = features_pred.squeeze()\n",
    "        \n",
    "        diff = e_sum_pred - e_sum\n",
    "        energy_diff.append(diff.cpu().numpy())\n",
    "        energy_sums.append(e_sum.cpu().numpy())\n",
    "\n",
    "energy_diff = np.hstack(energy_diff)\n",
    "energy_sums = np.hstack(energy_sums)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax = axes[0]\n",
    "frac_energy_diff = energy_diff/energy_sums\n",
    "ax.hist(frac_energy_diff, bins=30, density=True)\n",
    "ax.set_xlabel(r'$\\frac{E_{pred} - E_{true}}{E_{true}}$')\n",
    "ax.set_ylabel('Density')\n",
    "ax.text(0.6, 0.8, f' mean = {frac_energy_diff.mean():.2f} \\n std. err. = {frac_energy_diff.std():.2f}', transform=ax.transAxes)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.hexbin(energy_sums, frac_energy_diff, gridsize=30, mincnt=1, norm=LogNorm())\n",
    "ax.set_ylabel(r'$\\frac{E_{pred} - E_{true}}{E_{true}}$', size=16)\n",
    "ax.set_xlabel(r'$E_{true}$')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'plots/ae_energy_resolution_{scenario}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan over decoder\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(8, 10, facecolor='white', figsize=(12, 5), sharey=False, sharex=False)\n",
    "    for i in range(8):\n",
    "        test_values = np.linspace(-10, 10, 10)\n",
    "        test_values = \n",
    "        images = images.unsqueeze(1).to(device)\n",
    "        images_pred = model.decode(images)\n",
    "            image = image.squeeze().cpu().numpy()\n",
    "            encoded_image = encoded_image.squeeze().cpu().numpy()\n",
    "            image_pred = image_pred.squeeze().cpu().numpy().reshape(image.shape)\n",
    "            energy_corr = image.sum()/image_pred.sum()\n",
    "            image_pred *= energy_corr\n",
    "\n",
    "            ax = axes[0][ix]\n",
    "            ax.imshow(image, norm=LogNorm(vmin=0.1, vmax=100))\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            if ix == 0:\n",
    "                ax.set_ylabel('input')\n",
    "\n",
    "            ax = axes[1][ix]\n",
    "            ax.imshow(encoded_image.reshape(-1, 2), norm=LogNorm(vmin=0.1, vmax=100))\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            if ix == 0:\n",
    "                ax.set_ylabel('encoded')\n",
    "\n",
    "            ax = axes[2][ix]\n",
    "            ax.imshow(image_pred*energy_corr, norm=LogNorm(vmin=0.1, vmax=100))\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            if ix == 0:\n",
    "                ax.set_ylabel('output')\n",
    "\n",
    "            #ax = axes[3][ix]\n",
    "            #image[image ==  0] = 0.1\n",
    "            #ax.imshow(abs(image - image_pred)/image, cmap='coolwarm')\n",
    "            #ax.set_xticks([])\n",
    "            #ax.set_yticks([])\n",
    "            #if ix == 0:\n",
    "            #    ax.set_ylabel('input - output')\n",
    "\n",
    "            #plt.colorbar()\n",
    "\n",
    "            if ix == 9: break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'plots/ae_encoding_comparisons_modular_{scenario}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {
    "height": "4px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
