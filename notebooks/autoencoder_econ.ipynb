{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/naodell/work/hgcal/analysis\n"
     ]
    }
   ],
   "source": [
    "# imports and setup\n",
    "%cd '/home/naodell/work/hgcal/analysis'\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('default')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from utils.geometry_tools import conv_mask\n",
    "from models.autoencoder import AutoEncoderWafer, Autoencoder\n",
    "from datasets.hgcal_tc_dataset import HGCalTCModuleDataset\n",
    "\n",
    "#%connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of events: 67047\n"
     ]
    }
   ],
   "source": [
    "# get the data\n",
    "input_dir = 'local_data/econ_training_data/single_photon_data/'\n",
    "input_filenames = [f'{input_dir}/{f}' for f in os.listdir(input_dir)]\n",
    "hgcal_data = HGCalTCModuleDataset(input_filenames)\n",
    "\n",
    "# sample from dataframe according to event weights; split into testing and training sets\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# training sample\n",
    "batch_size = 4\n",
    "n_total = len(hgcal_data)\n",
    "split = round(0.8*n_total)\n",
    "train_loader = DataLoader(hgcal_data[:split],  batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(hgcal_data[split:],  batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "print(f'Total number of events: {n_total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [],
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Autoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): ConvTranspose2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): ConvTranspose2d(8, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define and setup the NN model\n",
    "n_flat_dimensions = np.product(hgcal_data[0].shape)\n",
    "#model = AutoEncoderWafer(n_flat_dimensions, device).to(device)\n",
    "model = Autoencoder().to(device)\n",
    "print(device, model, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d5c6baa9a649478872dd6445a65b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c062acd3032c4e7d84fdac637cd4ff2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13410 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6c70a5781a40d685fbc6cc4d8248cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3353 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a4b759ea0c4eca95b3700f18760952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13410 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# optimize NN weights\n",
    "n_epochs = 500\n",
    "n_events = len(train_loader)\n",
    "\n",
    "# define loss and configure optimizer\n",
    "loss_fn = nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-2, weight_decay=1e-3)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "tb_writer = SummaryWriter(log_dir='logs')\n",
    "\n",
    "pbar1 = tqdm(range(n_epochs), total=n_epochs, leave=False, position=0)\n",
    "pbar1.set_postfix({'avg. loss':'?'})\n",
    "for iepoch in pbar1:\n",
    "    model.train()\n",
    "    pbar2 = tqdm(train_loader, total=n_events, leave=False, position=1)\n",
    "    pbar2.set_postfix({'loss':'?'})\n",
    "    avg_loss = 0\n",
    "    for jevent, features in enumerate(pbar2):\n",
    "        features = features.unsqueeze(1).to(device)\n",
    "        #targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        features_pred = model(features)\n",
    "        loss = loss_fn(features_pred, features)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #pbar2.set_postfix({'loss':f'{loss.item():.3f}'})\n",
    "        #tb_writer.add_scalar('training loss', loss.item(), iepoch*n_events + jevent)\n",
    "        \n",
    "        avg_loss += loss.item()\n",
    "        if jevent%1000 == 0:\n",
    "            avg_loss /= 1000\n",
    "            pbar2.set_postfix({'loss':f'{loss.item():.3f}'})\n",
    "            #tb_writer.add_scalar('training loss', avg_loss, iepoch*(n_events//1000) + jevent/1000)\n",
    "            tb_writer.add_scalar('training loss', loss.item(), iepoch*(n_events//1000) + jevent/1000)\n",
    "            avg_loss = 0\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        n_test_events = len(test_loader)\n",
    "        for features in tqdm(test_loader, total=n_test_events, leave=False):\n",
    "            features = features.unsqueeze(1).to(device)\n",
    "            #targets = targets.to(device)\n",
    "            features_pred = model(features)\n",
    "            #print(features_pred.shape, features.shape)\n",
    "            test_loss += loss_fn(features_pred, features)\n",
    "            \n",
    "        avg_loss = test_loss.item()/n_test_events\n",
    "        pbar1.set_postfix({'avg loss':f'{avg_loss:.3f}'})\n",
    "        tb_writer.add_scalar('test loss', avg_loss, iepoch)\n",
    "        tb_writer.add_graph(model, features)\n",
    "        \n",
    "        #images = torchvision.utils.make_grid(features)\n",
    "        #images_pred = torchvision.utils.make_grid(features_pred)\n",
    "        #tb_writer.add_image('input', images)\n",
    "        #tb_writer.add_image('output', images_pred)\n",
    "        \n",
    "        # write a checkpoint based on the performance of the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare images\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 4, facecolor='white', figsize=(12, 4), sharey=False, sharex=True)\n",
    "    images = iter(test_loader).next()\n",
    "    images = images.unsqueeze(1).to(device)\n",
    "    images_pred = model(images)\n",
    "    encoded_images = model.encoder(images)\n",
    "    for ix, (image, encoded_image, image_pred) in enumerate(zip(images, encoded_images, images_pred)):\n",
    "        image = image.squeeze().cpu().numpy()\n",
    "        encoded_image = encoded_image.squeeze().cpu().numpy()\n",
    "        image_pred = image_pred.squeeze().cpu().numpy().reshape(image.shape)\n",
    "        \n",
    "        ax = axes[0][ix]\n",
    "        ax.imshow(image, norm=LogNorm(vmin=0.1, vmax=100))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if ix == 0:\n",
    "            ax.set_ylabel('input')\n",
    "        \n",
    "        ax = axes[1][ix]\n",
    "        ax.imshow(encoded_image.reshape(2, 8), norm=LogNorm(vmin=0.1, vmax=100))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if ix == 0:\n",
    "            ax.set_ylabel('output')\n",
    "            \n",
    "        ax = axes[2][ix]\n",
    "        ax.imshow(image_pred, norm=LogNorm(vmin=0.1, vmax=100))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if ix == 0:\n",
    "            ax.set_ylabel('output')\n",
    "        \n",
    "        ax = axes[3][ix]\n",
    "        ax.imshow(abs(image - image_pred), norm=LogNorm(vmin=0.01, vmax=1), cmap='coolwarm')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if ix == 0:\n",
    "            ax.set_ylabel('input - output')\n",
    "            \n",
    "        #plt.colorbar()\n",
    "        \n",
    "        if ix == 9: break\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {
    "height": "4px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
